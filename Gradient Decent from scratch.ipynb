{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb26d398",
   "metadata": {},
   "source": [
    "## `Gradient Decent from scratch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd76d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15dd5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/(1+math.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a0506ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.88079708)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = np.vectorize(sigmoid)\n",
    "sigma(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96830d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820137900379085"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9594f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807970779778823"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7243ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11920292202211755"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9bb279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_descent(x,y):  # x => feature, y => target\n",
    "    w_curr = b_curr = 0\n",
    "    iter = 100\n",
    "    n = len(x)\n",
    "    learning_rate = 0.01\n",
    "    for i in range(iter):\n",
    "        y_pred = sigma(w_curr * x + b_curr)  # single neuron\n",
    "        \n",
    "        # loss function is for the particular node\n",
    "        # cost function is for entire neural network\n",
    "        cost = (1/n) * sum([val**2 for val in (y-y_pred)])\n",
    "        # n is number of features in x\n",
    "        adj_w = -(2/n) * sum(x*(y-y_pred)) \n",
    "        adj_b = -(2/n) * sum(y-y_pred)\n",
    "        w_curr = w_curr - learning_rate * adj_w\n",
    "        b_curr = b_curr - learning_rate * adj_b\n",
    "        print('Epochs Step: ',i,'weights: ',w_curr,'Bias: ',b_curr,'cost function: ',cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca8c2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4,5])\n",
    "y = np.array([5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d811aa",
   "metadata": {},
   "source": [
    "### `Classic example of Vanishing gradient `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8008c168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Step:  0 weights:  0.43 Bias:  0.13 cost function:  44.25\n",
      "Epochs Step:  1 weights:  0.8399872508776669 Bias:  0.25423114788434786 cost function:  40.32217449661123\n",
      "Epochs Step:  2 weights:  1.2433552969471178 Bias:  0.3761254437784959 cost function:  38.921719623082396\n",
      "Epochs Step:  3 weights:  1.6447460269103016 Bias:  0.49709183424988374 cost function:  38.43509442366127\n",
      "Epochs Step:  4 weights:  2.0454128453803175 Bias:  0.6176223636844771 cost function:  38.22815197925876\n",
      "Epochs Step:  5 weights:  2.4457618944638226 Bias:  0.7379242181282782 cost function:  38.126327446089626\n",
      "Epochs Step:  6 weights:  2.8459538641667876 Bias:  0.8580990275394271 cost function:  38.07195893092668\n",
      "Epochs Step:  7 weights:  3.246062495207539 Bias:  0.9782012195395684 cost function:  38.04163661866746\n",
      "Epochs Step:  8 weights:  3.6461250310988915 Bias:  1.098261289437309 cost function:  38.02431623942163\n",
      "Epochs Step:  9 weights:  4.046161421829583 Bias:  1.2182967230251378 cost function:  38.01428403907876\n",
      "Epochs Step:  10 weights:  4.44618274719271 Bias:  1.338317673590805 cost function:  38.00842300305014\n",
      "Epochs Step:  11 weights:  4.846195302392589 Bias:  1.458330081166253 cost function:  38.00497967224275\n",
      "Epochs Step:  12 weights:  5.246202717391438 Bias:  1.5783374377923856 cost function:  38.002949153655926\n",
      "Epochs Step:  13 weights:  5.646207105935257 Bias:  1.698341803194898 cost function:  38.00174871084585\n",
      "Epochs Step:  14 weights:  6.0462097070331895 Bias:  1.8183443951027842 cost function:  38.00103776554254\n",
      "Epochs Step:  15 weights:  6.446211250224491 Bias:  1.9383459346402423 cost function:  38.00061620985477\n",
      "Epochs Step:  16 weights:  6.846212166388758 Bias:  2.0583468493506647 cost function:  38.00036603997893\n",
      "Epochs Step:  17 weights:  7.246212710546144 Bias:  2.1783473929292736 cost function:  38.00021749300682\n",
      "Epochs Step:  18 weights:  7.646213033849305 Bias:  2.2983477160019437 cost function:  38.00012925342\n",
      "Epochs Step:  19 weights:  8.04621322597545 Bias:  2.4183479080362758 cost function:  38.00007682337462\n",
      "Epochs Step:  20 weights:  8.446213340164567 Bias:  2.538348022188816 cost function:  38.00004566483672\n",
      "Epochs Step:  21 weights:  8.846213408038773 Bias:  2.658348090048448 cost function:  38.00002714536763\n",
      "Epochs Step:  22 weights:  9.24621344838594 Bias:  2.778348130389809 cost function:  38.000016137145515\n",
      "Epochs Step:  23 weights:  9.646213472370981 Bias:  2.898348154372535 cost function:  38.00000959332905\n",
      "Epochs Step:  24 weights:  10.046213486629707 Bias:  3.018348168630339 cost function:  38.000005703216324\n",
      "Epochs Step:  25 weights:  10.446213495106463 Bias:  3.1383481771067276 cost function:  38.000003390593115\n",
      "Epochs Step:  26 weights:  10.846213500145929 Bias:  3.258348182146047 cost function:  38.000002015742744\n",
      "Epochs Step:  27 weights:  11.24621350314194 Bias:  3.3783481851419985 cost function:  38.000001198386656\n",
      "Epochs Step:  28 weights:  11.646213504923107 Bias:  3.4983481869231423 cost function:  38.00000071245996\n",
      "Epochs Step:  29 weights:  12.046213505982038 Bias:  3.6183481879820647 cost function:  38.00000042356987\n",
      "Epochs Step:  30 weights:  12.446213506611592 Bias:  3.738348188611614 cost function:  38.00000025182011\n",
      "Epochs Step:  31 weights:  12.846213506985872 Bias:  3.8583481889858935 cost function:  38.00000014971187\n",
      "Epochs Step:  32 weights:  13.24621350720839 Bias:  3.97834818920841 cost function:  38.00000008900664\n",
      "Epochs Step:  33 weights:  13.646213507340681 Bias:  4.0983481893407 cost function:  38.00000005291622\n",
      "Epochs Step:  34 weights:  14.046213507419331 Bias:  4.218348189419349 cost function:  38.000000031459756\n",
      "Epochs Step:  35 weights:  14.44621350746609 Bias:  4.338348189466108 cost function:  38.00000001870347\n",
      "Epochs Step:  36 weights:  14.84621350749389 Bias:  4.458348189493907 cost function:  38.00000001111959\n",
      "Epochs Step:  37 weights:  15.246213507510417 Bias:  4.578348189510434 cost function:  38.000000006610826\n",
      "Epochs Step:  38 weights:  15.646213507520242 Bias:  4.69834818952026 cost function:  38.00000000393027\n",
      "Epochs Step:  39 weights:  16.046213507526083 Bias:  4.818348189526102 cost function:  38.00000000233663\n",
      "Epochs Step:  40 weights:  16.446213507529556 Bias:  4.938348189529575 cost function:  38.000000001389175\n",
      "Epochs Step:  41 weights:  16.846213507531623 Bias:  5.05834818953164 cost function:  38.00000000082589\n",
      "Epochs Step:  42 weights:  17.24621350753285 Bias:  5.178348189532867 cost function:  38.000000000491006\n",
      "Epochs Step:  43 weights:  17.64621350753358 Bias:  5.2983481895335975 cost function:  38.00000000029191\n",
      "Epochs Step:  44 weights:  18.046213507534016 Bias:  5.418348189534031 cost function:  38.00000000017355\n",
      "Epochs Step:  45 weights:  18.446213507534274 Bias:  5.538348189534289 cost function:  38.000000000103185\n",
      "Epochs Step:  46 weights:  18.84621350753443 Bias:  5.6583481895344425 cost function:  38.00000000006135\n",
      "Epochs Step:  47 weights:  19.24621350753452 Bias:  5.778348189534534 cost function:  38.00000000003647\n",
      "Epochs Step:  48 weights:  19.646213507534576 Bias:  5.898348189534588 cost function:  38.00000000002168\n",
      "Epochs Step:  49 weights:  20.046213507534606 Bias:  6.0183481895346205 cost function:  38.000000000012896\n",
      "Epochs Step:  50 weights:  20.446213507534626 Bias:  6.138348189534639 cost function:  38.00000000000767\n",
      "Epochs Step:  51 weights:  20.84621350753464 Bias:  6.258348189534651 cost function:  38.00000000000456\n",
      "Epochs Step:  52 weights:  21.246213507534645 Bias:  6.378348189534657 cost function:  38.00000000000271\n",
      "Epochs Step:  53 weights:  21.64621350753465 Bias:  6.498348189534661 cost function:  38.00000000000161\n",
      "Epochs Step:  54 weights:  22.046213507534652 Bias:  6.618348189534664 cost function:  38.00000000000096\n",
      "Epochs Step:  55 weights:  22.446213507534654 Bias:  6.738348189534665 cost function:  38.00000000000057\n",
      "Epochs Step:  56 weights:  22.846213507534657 Bias:  6.858348189534666 cost function:  38.00000000000034\n",
      "Epochs Step:  57 weights:  23.24621350753466 Bias:  6.978348189534666 cost function:  38.000000000000206\n",
      "Epochs Step:  58 weights:  23.646213507534657 Bias:  7.098348189534666 cost function:  38.00000000000012\n",
      "Epochs Step:  59 weights:  24.046213507534656 Bias:  7.218348189534666 cost function:  38.00000000000007\n",
      "Epochs Step:  60 weights:  24.446213507534654 Bias:  7.338348189534666 cost function:  38.00000000000005\n",
      "Epochs Step:  61 weights:  24.846213507534653 Bias:  7.458348189534666 cost function:  38.00000000000002\n",
      "Epochs Step:  62 weights:  25.24621350753465 Bias:  7.578348189534666 cost function:  38.000000000000014\n",
      "Epochs Step:  63 weights:  25.64621350753465 Bias:  7.698348189534666 cost function:  38.000000000000014\n",
      "Epochs Step:  64 weights:  26.04621350753465 Bias:  7.8183481895346665 cost function:  38.00000000000001\n",
      "Epochs Step:  65 weights:  26.446213507534647 Bias:  7.938348189534667 cost function:  38.0\n",
      "Epochs Step:  66 weights:  26.846213507534646 Bias:  8.058348189534666 cost function:  38.0\n",
      "Epochs Step:  67 weights:  27.246213507534645 Bias:  8.178348189534665 cost function:  38.0\n",
      "Epochs Step:  68 weights:  27.646213507534643 Bias:  8.298348189534664 cost function:  38.0\n",
      "Epochs Step:  69 weights:  28.04621350753464 Bias:  8.418348189534663 cost function:  38.0\n",
      "Epochs Step:  70 weights:  28.44621350753464 Bias:  8.538348189534663 cost function:  38.0\n",
      "Epochs Step:  71 weights:  28.84621350753464 Bias:  8.658348189534662 cost function:  38.0\n",
      "Epochs Step:  72 weights:  29.246213507534637 Bias:  8.778348189534661 cost function:  38.0\n",
      "Epochs Step:  73 weights:  29.646213507534636 Bias:  8.89834818953466 cost function:  38.0\n",
      "Epochs Step:  74 weights:  30.046213507534635 Bias:  9.01834818953466 cost function:  38.0\n",
      "Epochs Step:  75 weights:  30.446213507534633 Bias:  9.138348189534659 cost function:  38.0\n",
      "Epochs Step:  76 weights:  30.84621350753463 Bias:  9.258348189534658 cost function:  38.0\n",
      "Epochs Step:  77 weights:  31.24621350753463 Bias:  9.378348189534657 cost function:  38.0\n",
      "Epochs Step:  78 weights:  31.64621350753463 Bias:  9.498348189534656 cost function:  38.0\n",
      "Epochs Step:  79 weights:  32.04621350753463 Bias:  9.618348189534656 cost function:  38.0\n",
      "Epochs Step:  80 weights:  32.44621350753463 Bias:  9.738348189534655 cost function:  38.0\n",
      "Epochs Step:  81 weights:  32.84621350753463 Bias:  9.858348189534654 cost function:  38.0\n",
      "Epochs Step:  82 weights:  33.24621350753463 Bias:  9.978348189534653 cost function:  38.0\n",
      "Epochs Step:  83 weights:  33.646213507534625 Bias:  10.098348189534653 cost function:  38.0\n",
      "Epochs Step:  84 weights:  34.046213507534624 Bias:  10.218348189534652 cost function:  38.0\n",
      "Epochs Step:  85 weights:  34.44621350753462 Bias:  10.338348189534651 cost function:  38.0\n",
      "Epochs Step:  86 weights:  34.84621350753462 Bias:  10.45834818953465 cost function:  38.0\n",
      "Epochs Step:  87 weights:  35.24621350753462 Bias:  10.57834818953465 cost function:  38.0\n",
      "Epochs Step:  88 weights:  35.64621350753462 Bias:  10.698348189534649 cost function:  38.0\n",
      "Epochs Step:  89 weights:  36.04621350753462 Bias:  10.818348189534648 cost function:  38.0\n",
      "Epochs Step:  90 weights:  36.446213507534615 Bias:  10.938348189534647 cost function:  38.0\n",
      "Epochs Step:  91 weights:  36.846213507534614 Bias:  11.058348189534646 cost function:  38.0\n",
      "Epochs Step:  92 weights:  37.24621350753461 Bias:  11.178348189534645 cost function:  38.0\n",
      "Epochs Step:  93 weights:  37.64621350753461 Bias:  11.298348189534645 cost function:  38.0\n",
      "Epochs Step:  94 weights:  38.04621350753461 Bias:  11.418348189534644 cost function:  38.0\n",
      "Epochs Step:  95 weights:  38.44621350753461 Bias:  11.538348189534643 cost function:  38.0\n",
      "Epochs Step:  96 weights:  38.84621350753461 Bias:  11.658348189534642 cost function:  38.0\n",
      "Epochs Step:  97 weights:  39.246213507534605 Bias:  11.778348189534642 cost function:  38.0\n",
      "Epochs Step:  98 weights:  39.646213507534604 Bias:  11.89834818953464 cost function:  38.0\n",
      "Epochs Step:  99 weights:  40.0462135075346 Bias:  12.01834818953464 cost function:  38.0\n"
     ]
    }
   ],
   "source": [
    "Gradient_descent(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb851a0",
   "metadata": {},
   "source": [
    "## `END -----------------------------------------`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
